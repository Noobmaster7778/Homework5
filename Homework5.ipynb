{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOMEWORK 5\n",
    "This homework will look at image linear registration and its use in digital photography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1:\n",
    "If you can't do this (or don't want to), I am giving data files you can use.  I just thought it would be more fun to use your own.\n",
    "\n",
    "Go out and enjoy the last few days of nice weather before it starts to get cold!\n",
    "Using your phone (or whatever), collect a set of images that we will use in this homework set.  \n",
    "\n",
    "* (1) Pick something that has distinct features and take several (5 is good) pictures of this from slightly different angles.  The images should have about 50% overlap (or more) with the one before it.  We are going use these to do image stitching to make a panorama.\n",
    "\n",
    "* (2) [If possible] Pick an object that has alot of light-dark contrast.  For example, a dimly lit room, or in shadows, or outside where the sun is really bright.  Take a set of images with the same view with different exposures (it might be good to prop the camera/phone to help keep it steady).  We are going to use this to do High Dynamic Range Imaging (HDRI)\n",
    "\n",
    "On newer iPhone (14+) you can do this in the camera app.  Android phones allow this in \"professional\" or \"manual\" mode of the camera app.  Or there are a bunch of free camera apps.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2:\n",
    "Using two of the images you took from part (1) above:\n",
    "\n",
    "* Calculate features from both images using the cv2.goodFeaturesToTrack function.  \n",
    "Use the 25_VideoMotionCorrection.ipynb (Lecture 12; LectureNotebooks Git) as a demo.\n",
    "\n",
    "* Display the total features found on both images \n",
    "\n",
    "* Apply the feature matching code and display the matched features between the two images (see lecture 11 notebooks)\n",
    "\n",
    "* Finally, warp the moveable image and display (in calculating the registration, you set one image as the target and one as \n",
    "the moveable based on the order you gave them in the function call). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "Using all the images you took in (1) of problem 1, we will not make a panorama.  This is basically the same thing \n",
    "you did for problem 2, but done iteratively to align all the images with each other.  Of course, there is a function in\n",
    "openCV for this.   \n",
    "\n",
    "stitcher=cv2.Stitcher.create()\n",
    "\n",
    "(dummy,output)=stitcher.stitch(img_list) \n",
    "\n",
    "Note- I would not use more than 5 images because the sticher can take a bit of time if you have a lot \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of loading multiple image files into a list using glob\n",
    "# Replace with your own images.  If you didn't collect your own, you can use the Cliffs_of_Moher images \n",
    "(which is a spot on the western coast of Ireland that I visited)\n",
    "\n",
    "import glob\n",
    "\n",
    "img_filenames = glob.glob(os.path.relpath(\"Data/Moher/Cliffs_of_Moher*.jpeg\"))\n",
    "img_filenames=sorted(img_filenames)\n",
    "\n",
    "img_list = [cv2.imread(file) for file in img_filenames]\n",
    "\n",
    "img_list=[cv2.cvtColor(img_list[idx],cv2.COLOR_BGR2RGB) for idx in range(0,len(img_list))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4.\n",
    "HDRI combines images with multiple exposures in order to increase the dynamic range of the camera (e.g. able to see both dim and bright objects).  \n",
    "\n",
    "[1390 & 2390 students]\n",
    "* Using the images from (2) of problem 1, (or use the ones in Data/Trinity_Library) combine your images into one HDR photo and display it\n",
    "\n",
    "* Use the Mertens function in openCV (e.g)\n",
    "\n",
    "*           merge_mertens = cv2.createMergeMertens()\n",
    "*           hdr_img = merge_mertens.process(img_list)\n",
    "\n",
    "Note, the Mertens function does not need the exposure times to be provided\n",
    "\n",
    "\n",
    "[1390 & 2390 students]\n",
    "* For the same images used in the first part of this problem, apply the MTB motion correction and repeat/show the HDR image\n",
    "\n",
    "*           alignMTB = cv2.createAlignMTB()\n",
    "*           alignMTB.process(img_list_In,img_list_Out)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[ECE2390 students]\n",
    "* Repeat HDR method using the Debevec method.  If you use the Trinity_Library images, the exposure times are [1/50s,1/33s,1/25s,1/20s,1/17s] and EV stops are [-2,-1,0,1,2]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
